{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1e521e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 04_ReturnForecasting.ipynb\n",
    "# Objective: Predict next-day returns for each sector, conditioned on market regimes\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aabdb29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# Step 1: Load Data\n",
    "# ------------------------\n",
    "features = pd.read_csv(\"../data/processed/feature_matrix.csv\", parse_dates=['Date'], index_col='Date')\n",
    "regimes = pd.read_csv(\"../data/processed/regime_labels.csv\", parse_dates=['Date'], index_col='Date')\n",
    "returns = pd.read_csv(\"../data/processed/returns_data.csv\", parse_dates=['Date'], index_col='Date')\n",
    "\n",
    "# Align all data\n",
    "df = features.join(regimes).join(returns)\n",
    "\n",
    "# Create target: next-day returns\n",
    "targets = returns.shift(-1).add_suffix(\"_t+1\")\n",
    "df = df.join(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a005004c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2209, 56)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c87089e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any resulting NaNs\n",
    "df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82752c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2208, 56)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8b2d93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Regime 0 ---\n",
      "NIFTY_IT: RMSE = 0.02000, R^2 = -2.3558\n",
      "NIFTY_BANK: RMSE = 0.00789, R^2 = -0.0015\n",
      "NIFTY_FMCG: RMSE = 0.01137, R^2 = -0.0876\n",
      "NIFTY_PHARMA: RMSE = 0.00987, R^2 = -0.0986\n",
      "NIFTY_AUTO: RMSE = 0.00976, R^2 = -0.0066\n",
      "NIFTY_METAL: RMSE = 0.01371, R^2 = -0.0465\n",
      "\n",
      "--- Regime 1 ---\n",
      "NIFTY_IT: RMSE = 0.01302, R^2 = -0.0084\n",
      "NIFTY_BANK: RMSE = 0.01114, R^2 = -0.0046\n",
      "NIFTY_FMCG: RMSE = 0.00917, R^2 = -0.0167\n",
      "NIFTY_PHARMA: RMSE = 0.01344, R^2 = -0.0431\n",
      "NIFTY_AUTO: RMSE = 0.01301, R^2 = -0.0420\n",
      "NIFTY_METAL: RMSE = 0.01802, R^2 = -0.0373\n",
      "\n",
      "--- Regime 2 ---\n",
      "NIFTY_IT: RMSE = 0.01840, R^2 = -0.0892\n",
      "NIFTY_BANK: RMSE = 0.02296, R^2 = -0.1118\n",
      "NIFTY_FMCG: RMSE = 0.01338, R^2 = 0.0213\n",
      "NIFTY_PHARMA: RMSE = 0.01552, R^2 = -0.0297\n",
      "NIFTY_AUTO: RMSE = 0.02003, R^2 = -0.0580\n",
      "NIFTY_METAL: RMSE = 0.02403, R^2 = 0.0152\n"
     ]
    }
   ],
   "source": [
    "# ------------------------\n",
    "# Step 2: Model Training per Regime (with Sanitation)\n",
    "# ------------------------\n",
    "\n",
    "def sanitize_features(X, method='median', cap=5.0):\n",
    "    \"\"\" Replace inf/nan using contextual imputation and optional capping \"\"\"\n",
    "    X = X.copy()\n",
    "    for col in X.columns:\n",
    "        x = X[col].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "        if method == 'median':\n",
    "            fill_val = np.nanmedian(x)\n",
    "        elif method == 'mean':\n",
    "            fill_val = np.nanmean(x)\n",
    "        else:\n",
    "            fill_val = 0.0\n",
    "\n",
    "        X[col] = np.nan_to_num(x, nan=fill_val)\n",
    "        \n",
    "        # Optional: clip to cap outliers (e.g., ±5×std)\n",
    "        std = np.std(X[col])\n",
    "        mean = np.mean(X[col])\n",
    "        if std > 0:\n",
    "            X[col] = np.clip(X[col], mean - cap * std, mean + cap * std)\n",
    "        \n",
    "    return X\n",
    "\n",
    "\n",
    "sector_list = ['NIFTY_IT', 'NIFTY_BANK', 'NIFTY_FMCG', 'NIFTY_PHARMA', 'NIFTY_AUTO', 'NIFTY_METAL']\n",
    "results = []\n",
    "models = {}\n",
    "\n",
    "for regime in sorted(df['vol_regime'].unique()):\n",
    "    print(f\"\\n--- Regime {regime} ---\")\n",
    "    regime_df = df[df['vol_regime'] == regime]\n",
    "\n",
    "    for sector in sector_list:\n",
    "        # Extract raw features and sanitize them\n",
    "        X_raw = regime_df[features.columns]\n",
    "        X = sanitize_features(X_raw, method='median', cap=5.0)\n",
    "\n",
    "        y = regime_df[f\"{sector}_t+1\"]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        model = Ridge(alpha=1.0)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"{sector}: RMSE = {rmse:.5f}, R^2 = {r2:.4f}\")\n",
    "        results.append({'regime': regime, 'sector': sector, 'rmse': rmse, 'r2': r2})\n",
    "\n",
    "        # Save model for later use\n",
    "        model_name = f\"{sector}_regime{regime}_ridge_model.joblib\"\n",
    "        model_path = os.path.join(\"../scripts/models\", model_name)\n",
    "        joblib.dump(model, model_path)\n",
    "        models[(sector, regime)] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1457580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Summary of Forecasting Results ===\n",
      "            rmse        r2\n",
      "regime                    \n",
      "0       0.012097 -0.432755\n",
      "1       0.012966 -0.025351\n",
      "2       0.019054 -0.042011\n"
     ]
    }
   ],
   "source": [
    "# ------------------------\n",
    "# Step 3: Result Summary\n",
    "# ------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n=== Summary of Forecasting Results ===\")\n",
    "print(results_df.groupby('regime')[['rmse', 'r2']].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a726b984",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m y \u001b[38;5;241m=\u001b[39m regime_df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexample_sector\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_t+1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m models[(example_sector, example_regime)]\n\u001b[1;32m---> 11\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(y\u001b[38;5;241m.\u001b[39mindex, y, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\iamta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:297\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    284\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;124;03m    Predict using the linear model.\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;124;03m        Returns predicted values.\u001b[39;00m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\iamta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:276\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    274\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 276\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    277\u001b[0m     coef_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m coef_\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\iamta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2944\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2942\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m-> 2944\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2945\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m   2946\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\iamta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1107\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[1;32m-> 1107\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1116\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\iamta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:120\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\iamta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:169\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    168\u001b[0m     )\n\u001b[1;32m--> 169\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# ------------------------\n",
    "# Step 4: Plot Predicted vs Actual (example sector)\n",
    "# ------------------------\n",
    "example_sector = 'NIFTY_IT'\n",
    "example_regime = 0\n",
    "\n",
    "regime_df = df[df['vol_regime'] == example_regime]\n",
    "X = regime_df[features.columns]\n",
    "y = regime_df[f\"{example_sector}_t+1\"]\n",
    "model = models[(example_sector, example_regime)]\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(y.index, y, label='Actual')\n",
    "plt.plot(y.index, y_pred, label='Predicted', alpha=0.7)\n",
    "plt.title(f\"{example_sector} - Regime {example_regime} Return Prediction\")\n",
    "plt.legend()\n",
    "plt.savefig(\"../results/plots/return_forecast_example.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763b72d9",
   "metadata": {},
   "source": [
    "ReturnForecasting ✅ Final Try: XGBoost and MLPRegressor (Side-by-side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74b03d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Regime 0 ---\n",
      "NIFTY_IT: R² XGBoost = -241.0908 | R² MLP = -177053.2979\n",
      "NIFTY_BANK: R² XGBoost = -0.0495 | R² MLP = -333953.9300\n",
      "NIFTY_FMCG: R² XGBoost = -0.1076 | R² MLP = -173998.1583\n",
      "NIFTY_PHARMA: R² XGBoost = -0.0951 | R² MLP = -233378.5034\n",
      "NIFTY_AUTO: R² XGBoost = -0.0676 | R² MLP = -223943.3419\n",
      "NIFTY_METAL: R² XGBoost = -0.1509 | R² MLP = -114724.5493\n",
      "\n",
      "--- Regime 1 ---\n",
      "NIFTY_IT: R² XGBoost = -0.0037 | R² MLP = -46953.7101\n",
      "NIFTY_BANK: R² XGBoost = -0.0094 | R² MLP = -45492.4320\n",
      "NIFTY_FMCG: R² XGBoost = -0.1064 | R² MLP = -93067.6856\n",
      "NIFTY_PHARMA: R² XGBoost = -0.0614 | R² MLP = -33313.4867\n",
      "NIFTY_AUTO: R² XGBoost = -0.0235 | R² MLP = -47356.9823\n",
      "NIFTY_METAL: R² XGBoost = -0.0165 | R² MLP = -25194.9149\n",
      "\n",
      "--- Regime 2 ---\n",
      "NIFTY_IT: R² XGBoost = -0.2130 | R² MLP = -24292.0259\n",
      "NIFTY_BANK: R² XGBoost = -0.1208 | R² MLP = -15868.5541\n",
      "NIFTY_FMCG: R² XGBoost = -0.0879 | R² MLP = -41167.9286\n",
      "NIFTY_PHARMA: R² XGBoost = -0.0714 | R² MLP = -32167.7371\n",
      "NIFTY_AUTO: R² XGBoost = -0.0970 | R² MLP = -19979.9206\n",
      "NIFTY_METAL: R² XGBoost = -0.1301 | R² MLP = -12834.8505\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def sanitize_features(X, method='median', cap=5.0):\n",
    "    \"\"\" Replace inf/nan using contextual imputation and optional capping \"\"\"\n",
    "    X = X.copy()\n",
    "    for col in X.columns:\n",
    "        x = X[col].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "        fill_val = np.nanmedian(x) if method == 'median' else np.nanmean(x)\n",
    "        X[col] = np.nan_to_num(x, nan=fill_val)\n",
    "\n",
    "        std = np.std(X[col])\n",
    "        mean = np.mean(X[col])\n",
    "        X[col] = np.clip(X[col], mean - cap * std, mean + cap * std)\n",
    "\n",
    "    return X\n",
    "\n",
    "sector_list = ['NIFTY_IT', 'NIFTY_BANK', 'NIFTY_FMCG', 'NIFTY_PHARMA', 'NIFTY_AUTO', 'NIFTY_METAL']\n",
    "results = []\n",
    "\n",
    "for regime in sorted(df['vol_regime'].unique()):\n",
    "    print(f\"\\n--- Regime {regime} ---\")\n",
    "    regime_df = df[df['vol_regime'] == regime]\n",
    "\n",
    "    for sector in sector_list:\n",
    "        X = regime_df[features.columns]\n",
    "        y = regime_df[f\"{sector}_t+1\"]\n",
    "        X = sanitize_features(X)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Option 1: XGBoost\n",
    "        xgb_model = XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.05, random_state=42)\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "        y_pred_xgb = xgb_model.predict(X_test)\n",
    "        r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "        # Option 2: MLP Regressor\n",
    "        mlp_model = MLPRegressor(hidden_layer_sizes=(64, 32), max_iter=500, random_state=42)\n",
    "        mlp_model.fit(X_train, y_train)\n",
    "        y_pred_mlp = mlp_model.predict(X_test)\n",
    "        r2_mlp = r2_score(y_test, y_pred_mlp)\n",
    "\n",
    "        print(f\"{sector}: R² XGBoost = {r2_xgb:.4f} | R² MLP = {r2_mlp:.4f}\")\n",
    "        results.append({\n",
    "            'regime': regime, 'sector': sector,\n",
    "            'r2_xgb': r2_xgb, 'r2_mlp': r2_mlp\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbc791d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
